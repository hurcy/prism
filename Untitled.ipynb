{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.layers import GRU\n",
    "from keras.optimizers import adam\n",
    "from keras.callbacks import History\n",
    "from keras.layers import Input, Dense, Masking, Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "class Autoencoder:\n",
    "  def __init__(self, train_measure):\n",
    "    self.train_measure = train_measure\n",
    "    self.build_model()\n",
    "\n",
    "  def build_model(self):\n",
    "    \n",
    "    #인코딩될 표현(representation)의 크기\n",
    "#     encoding_dims=[3,6,9,12]\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10,\n",
    "                                   verbose=0, mode='auto')\n",
    "\n",
    "    batch_size=int(np.floor(len(self.train_measure)/5))\n",
    "    epochs=10\n",
    "    \n",
    "    # 입력 플레이스홀더\n",
    "    input_img = Input(shape=(self.train_measure.shape[1],))\n",
    "    # \"encoded\"는 입력의 인코딩된 표현\n",
    "    encoded1 = Dense(64, activation='tanh', name='encoder1' )(input_img)\n",
    "    encoded2 = Dense(64, activation='relu', name='encoder2' )(encoded1)\n",
    "\n",
    "    # \"decoded\"는 입력의 손실있는 재구성 (lossy reconstruction)\n",
    "    decoded1 = Dense(self.train_measure.shape[1], activation='tanh', name='decoder1')(encoded2)\n",
    "\n",
    "    # 입력을 입력의 재구성으로 매핑할 모델\n",
    "    autoencoder = Model(input_img, decoded2)\n",
    "\n",
    "    autoencoder.compile(loss='mean_squared_error',optimizer=adam())\n",
    "\n",
    "    print(autoencoder.summary())\n",
    "\n",
    "    self.model = autoencoder\n",
    "\n",
    "  def load(self, path):\n",
    "    model_path = tf.train.latest_checkpoint(path)\n",
    "    if model_path is None:\n",
    "      file_name = sorted([file_name for file_name in os.listdir(path) if file_name.endswith('.hdf5')])[-1]\n",
    "      model_path = os.path.join(path, file_name)\n",
    "    \n",
    "    self.model = load_model(model_path)\n",
    "\n",
    "  def train(self, train_measure, valid_measure, epochs, verbose, callbacks):\n",
    "\n",
    "    self.model.fit(train_measure, train_measure, batch_size=batch_size, \n",
    "                                        epochs=epochs, verbose=verbose, \n",
    "                                        validation_data=(valid_measure, valid_measure),\n",
    "                                        callbacks=callbacks)\n",
    "                              \n",
    "  def predict(self):\n",
    "    self.model.layers[1]\n",
    "    self.model.layers[2]\n",
    "    \n",
    "    input_img = Input(shape=(self.train_measure.shape[1],))\n",
    "    layer1=self.model.layers[1]\n",
    "    layer2=self.model.layers[2]\n",
    "\n",
    "    encoder= Model(input_img, layer2(layer1(input_img)))\n",
    "    output=encoder.predict(self.train_measure)\n",
    "    return output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "park",
   "language": "python",
   "name": "park"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
